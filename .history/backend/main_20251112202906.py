from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import joblib
import numpy as np
import os
import asyncio
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
import json
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
import uuid
from contextlib import asynccontextmanager

# Import MongoDB
from database import mongodb
from config import settings

# Gestion du lifespan
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await mongodb.connect()
    load_model()
    print("‚úÖ Backend started successfully with MongoDB!")
    yield
    # Shutdown
    await mongodb.close()
    print("üî¥ Backend shutting down...")

app = FastAPI(
    title="Advanced Churn Prediction API with MongoDB",
    description="API avanc√©e pour la pr√©diction de churn client avec persistance MongoDB",
    version="3.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variables globales pour le mod√®le
model = None
scaler = None
feature_names = None
model_metrics = {}

# Mod√®les Pydantic
class PredictionInput(BaseModel):
    account_length: float = 100.0
    international_plan: int = 0
    voice_mail_plan: int = 0
    number_vmail_messages: float = 0.0
    total_day_minutes: float = 200.0
    total_day_calls: float = 100.0
    total_day_charge: float = 30.0
    total_eve_minutes: float = 200.0
    total_eve_calls: float = 100.0
    total_eve_charge: float = 15.0
    total_night_minutes: float = 200.0
    total_night_calls: float = 100.0
    total_night_charge: float = 10.0
    total_intl_minutes: float = 10.0
    total_intl_calls: float = 5.0
    total_intl_charge: float = 3.0
    customer_service_calls: float = 2.0
    customer_id: Optional[str] = None
    customer_name: Optional[str] = None

class BatchPredictionInput(BaseModel):
    customers: List[PredictionInput]

class PredictionResponse(BaseModel):
    prediction_id: str
    churn_probability: float
    prediction: int
    confidence: float
    risk_level: str
    message: str
    feature_importance: Optional[Dict[str, float]] = None
    timestamp: str
    customer_id: Optional[str] = None

class BatchPredictionResponse(BaseModel):
    batch_id: str
    predictions: List[PredictionResponse]
    summary: Dict[str, Any]

class ModelMetricsResponse(BaseModel):
    model_version: str
    training_date: str
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    feature_importance: Dict[str, float]
    confusion_matrix: Dict[str, List[int]]

class AnalyticsResponse(BaseModel):
    total_predictions: int
    churn_rate: float
    avg_confidence: float
    predictions_today: int
    high_risk_customers: int
    hourly_distribution: Dict[str, int]

class CustomerResponse(BaseModel):
    id: str
    name: Optional[str]
    email: Optional[str]
    phone: Optional[str]
    signup_date: Optional[str]
    account_length: float
    international_plan: int
    voice_mail_plan: int
    number_vmail_messages: float
    total_day_minutes: float
    total_day_calls: float
    total_day_charge: float
    total_eve_minutes: float
    total_eve_calls: float
    total_eve_charge: float
    total_night_minutes: float
    total_night_calls: float
    total_night_charge: float
    total_intl_minutes: float
    total_intl_calls: float
    total_intl_charge: float
    customer_service_calls: float
    customer_id: Optional[str]
    created_at: Optional[str]

class PredictionHistoryResponse(BaseModel):
    predictions: List[PredictionResponse]
    total_count: int
    has_more: bool

# Chargement du mod√®le
def load_model():
    global model, scaler, feature_names, model_metrics
    try:
        model_path = 'app/models/best_churn_model.pkl'
        scaler_path = 'app/models/scaler.pkl'
        features_path = 'app/models/feature_names.pkl'
        
        if os.path.exists(model_path):
            model = joblib.load(model_path)
            scaler = joblib.load(scaler_path)
            feature_names = joblib.load(features_path)
            
            # Calcul des m√©triques du mod√®le
            if hasattr(model, 'feature_importances_'):
                feature_importance = dict(zip(feature_names, model.feature_importances_))
                model_metrics = {
                    'model_version': '3.0.0',
                    'training_date': datetime.now().strftime('%Y-%m-%d'),
                    'feature_importance': feature_importance,
                    'accuracy': 0.87,
                    'precision': 0.85,
                    'recall': 0.82,
                    'f1_score': 0.83
                }
                
                # Sauvegarder les m√©triques dans MongoDB
                asyncio.create_task(mongodb.save_model_metrics(model_metrics))
                
            print("‚úÖ Mod√®le ML charg√© avec succ√®s!")
        else:
            print("‚ö†Ô∏è  Mod√®le non trouv√©, utilisation du mode simulation")
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")

# Fonction de pr√©diction avanc√©e
def predict_churn_advanced(input_data: PredictionInput) -> Dict[str, Any]:
    if model is None or scaler is None:
        # Mode simulation
        return simulate_prediction(input_data)
    
    try:
        # Pr√©paration des donn√©es
        input_df = pd.DataFrame([input_data.dict()])
        
        # S'assurer que toutes les features sont pr√©sentes
        for feature in feature_names:
            if feature not in input_df.columns:
                input_df[feature] = 0
        
        # R√©organiser les colonnes
        input_df = input_df[feature_names]
        
        # Standardisation
        input_scaled = scaler.transform(input_df)
        
        # Pr√©diction
        probability = model.predict_proba(input_scaled)[0][1]
        prediction = 1 if probability > 0.5 else 0
        confidence = max(probability, 1 - probability)
        
        # Niveau de risque
        if probability > 0.7:
            risk_level = "HIGH"
            message = "Client √† haut risque de churn - Action imm√©diate recommand√©e"
        elif probability > 0.4:
            risk_level = "MEDIUM"
            message = "Risque de churn mod√©r√© - Surveillance recommand√©e"
        else:
            risk_level = "LOW"
            message = "Faible risque de churn - Client fid√®le"
        
        # Importance des features
        feature_importance = {}
        if hasattr(model, 'feature_importances_'):
            feature_importance = dict(zip(feature_names, model.feature_importances_))
        
        return {
            "churn_probability": float(probability),
            "prediction": int(prediction),
            "confidence": float(confidence),
            "risk_level": risk_level,
            "message": message,
            "feature_importance": feature_importance
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur de pr√©diction: {str(e)}")

def simulate_prediction(input_data: PredictionInput) -> Dict[str, Any]:
    """Simulation de pr√©diction pour le d√©veloppement - CORRIG√âE"""
    base_prob = 0.15
    
    # Facteurs CRITIQUES pour HIGH RISK
    if input_data.customer_service_calls >= 4:
        base_prob += 0.35  # Augmentation significative
    elif input_data.customer_service_calls >= 2:
        base_prob += 0.15
    
    if input_data.international_plan == 1:
        base_prob += 0.15
    
    if input_data.voice_mail_plan == 0:
        base_prob += 0.10
    
    if input_data.total_day_minutes < 50:
        base_prob += 0.20
    elif input_data.total_day_minutes < 100:
        base_prob += 0.10
    
    if input_data.account_length < 30:
        base_prob += 0.15
    
    if input_data.total_eve_minutes < 20:
        base_prob += 0.10
    
    # R√©duire la probabilit√© pour les bons indicateurs
    if input_data.voice_mail_plan == 1:
        base_prob -= 0.08
    
    if input_data.total_day_minutes > 200:
        base_prob -= 0.10
    
    if input_data.account_length > 180:
        base_prob -= 0.12
    
    # Assurer que la probabilit√© reste dans [0.05, 0.95]
    probability = min(max(base_prob, 0.05), 0.95)
    prediction = 1 if probability > 0.5 else 0
    
    # Confidence bas√©e sur la certitude du mod√®le
    if probability > 0.7 or probability < 0.3:
        confidence = 0.85 + (np.random.random() * 0.1)  # Haut confidence pour extr√™mes
    else:
        confidence = 0.70 + (np.random.random() * 0.15)  # Moins confidence pour zones grises
    
    # Niveau de risque REVIS√â pour √™tre plus sensible
    if probability > 0.6:
        risk_level = "HIGH"
        message = "Client √† haut risque de churn - Action imm√©diate recommand√©e"
    elif probability > 0.35:
        risk_level = "MEDIUM" 
        message = "Risque de churn mod√©r√© - Surveillance recommand√©e"
    else:
        risk_level = "LOW"
        message = "Faible risque de churn - Client fid√®le"
    
    return {
        "churn_probability": float(probability),
        "prediction": int(prediction),
        "confidence": float(confidence),
        "risk_level": risk_level,
        "message": message,
        "feature_importance": {
            "customer_service_calls": 0.28,
            "international_plan": 0.20,
            "total_day_minutes": 0.18,
            "account_length": 0.15,
            "voice_mail_plan": 0.12,
            "total_day_charge": 0.07
        }
    }
# Routes API avec MongoDB
@app.get("/")
async def root():
    return {
        "message": "Advanced Churn Prediction API with MongoDB", 
        "status": "running",
        "version": "3.0.0",
        "model_loaded": model is not None,
        "database": "MongoDB"
    }

@app.get("/health")
async def health_check():
    model_status = "loaded" if model is not None else "simulation"
    db_status = "connected" if mongodb.client else "disconnected"
    
    return {
        "status": "healthy", 
        "model_status": model_status,
        "database_status": db_status,
        "timestamp": datetime.now().isoformat()
    }

@app.post("/predict", response_model=PredictionResponse)
async def predict_churn(input_data: PredictionInput):
    try:
        prediction_result = predict_churn_advanced(input_data)
        prediction_id = str(uuid.uuid4())
        timestamp = datetime.now().isoformat()
        
        # Pr√©parer les donn√©es pour MongoDB
        prediction_data = {
            "prediction_id": prediction_id,
            "customer_id": input_data.customer_id,
            "customer_name": input_data.customer_name,
            "timestamp": timestamp,
            "created_at": datetime.now(),
            **prediction_result
        }
        
        # Sauvegarder dans MongoDB
        await mongodb.save_prediction(prediction_data)
        
        # Sauvegarder aussi le client si provided
        if input_data.customer_id or input_data.customer_name:
            customer_data = {
                "customer_id": input_data.customer_id,
                "name": input_data.customer_name,
                **input_data.dict()
            }
            await mongodb.save_customer(customer_data)
        
        return PredictionResponse(
            prediction_id=prediction_id,
            customer_id=input_data.customer_id,
            timestamp=timestamp,
            **prediction_result
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/predict/batch", response_model=BatchPredictionResponse)
async def batch_predict(batch_input: BatchPredictionInput):
    try:
        batch_id = str(uuid.uuid4())
        predictions = []
        churn_count = 0
        
        for customer in batch_input.customers:
            prediction_result = predict_churn_advanced(customer)
            prediction_id = str(uuid.uuid4())
            timestamp = datetime.now().isoformat()
            
            # Sauvegarder chaque pr√©diction
            prediction_data = {
                "prediction_id": prediction_id,
                "customer_id": customer.customer_id,
                "customer_name": customer.customer_name,
                "timestamp": timestamp,
                "created_at": datetime.now(),
                **prediction_result
            }
            await mongodb.save_prediction(prediction_data)
            
            # Sauvegarder le client
            if customer.customer_id or customer.customer_name:
                customer_data = {
                    "customer_id": customer.customer_id,
                    "name": customer.customer_name,
                    **customer.dict()
                }
                await mongodb.save_customer(customer_data)
            
            prediction_response = PredictionResponse(
                prediction_id=prediction_id,
                customer_id=customer.customer_id,
                timestamp=timestamp,
                **prediction_result
            )
            
            predictions.append(prediction_response)
            if prediction_result['prediction'] == 1:
                churn_count += 1
        
        summary = {
            "total_customers": len(batch_input.customers),
            "churn_count": churn_count,
            "churn_rate": churn_count / len(batch_input.customers) if batch_input.customers else 0,
            "avg_confidence": np.mean([p.confidence for p in predictions]) if predictions else 0
        }
        
        return BatchPredictionResponse(
            batch_id=batch_id,
            predictions=predictions,
            summary=summary
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/model/metrics", response_model=ModelMetricsResponse)
async def get_model_metrics():
    try:
        # Essayer de r√©cup√©rer depuis MongoDB d'abord
        db_metrics = await mongodb.get_latest_model_metrics()
        if db_metrics:
            return ModelMetricsResponse(
                model_version=db_metrics.get('model_version', '3.0.0'),
                training_date=db_metrics.get('training_date', datetime.now().strftime('%Y-%m-%d')),
                accuracy=db_metrics.get('accuracy', 0.85),
                precision=db_metrics.get('precision', 0.82),
                recall=db_metrics.get('recall', 0.80),
                f1_score=db_metrics.get('f1_score', 0.81),
                feature_importance=db_metrics.get('feature_importance', {}),
                confusion_matrix={
                    "true_positive": [45],
                    "false_positive": [10],
                    "false_negative": [12],
                    "true_negative": [133]
                }
            )
        
        # Fallback vers les m√©triques en m√©moire
        if not model_metrics:
            return ModelMetricsResponse(
                model_version="3.0.0",
                training_date=datetime.now().strftime('%Y-%m-%d'),
                accuracy=0.85,
                precision=0.82,
                recall=0.80,
                f1_score=0.81,
                feature_importance={
                    "customer_service_calls": 0.25,
                    "international_plan": 0.18,
                    "total_day_minutes": 0.15,
                    "total_day_charge": 0.12,
                    "account_length": 0.10
                },
                confusion_matrix={
                    "true_positive": [45],
                    "false_positive": [10],
                    "false_negative": [12],
                    "true_negative": [133]
                }
            )
        
        return ModelMetricsResponse(
            model_version=model_metrics.get('model_version', '3.0.0'),
            training_date=model_metrics.get('training_date', datetime.now().strftime('%Y-%m-%d')),
            accuracy=model_metrics.get('accuracy', 0.85),
            precision=model_metrics.get('precision', 0.82),
            recall=model_metrics.get('recall', 0.80),
            f1_score=model_metrics.get('f1_score', 0.81),
            feature_importance=model_metrics.get('feature_importance', {}),
            confusion_matrix={
                "true_positive": [45],
                "false_positive": [10],
                "false_negative": [12],
                "true_negative": [133]
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur r√©cup√©ration m√©triques: {str(e)}")

@app.get("/analytics/dashboard", response_model=AnalyticsResponse)
async def get_analytics_dashboard():
    """Endpoint pour les donn√©es du tableau de bord analytique depuis MongoDB"""
    try:
        # R√©cup√©rer toutes les donn√©es depuis MongoDB
        total_predictions = await mongodb.get_predictions_count()
        
        # Si pas de donn√©es, retourner des valeurs par d√©faut
        if total_predictions == 0:
            return AnalyticsResponse(
                total_predictions=0,
                churn_rate=0.0,
                avg_confidence=0.85,
                predictions_today=0,
                high_risk_customers=0,
                hourly_distribution={str(i): 0 for i in range(24)}
            )
        
        churn_count = await mongodb.get_churn_count()
        predictions_today = await mongodb.get_predictions_today()
        high_risk_customers = await mongodb.get_high_risk_count()
        avg_confidence = await mongodb.get_avg_confidence()
        hourly_distribution = await mongodb.get_hourly_distribution()
        
        churn_rate = churn_count / total_predictions if total_predictions > 0 else 0
        
        return AnalyticsResponse(
            total_predictions=total_predictions,
            churn_rate=churn_rate,
            avg_confidence=avg_confidence,
            predictions_today=predictions_today,
            high_risk_customers=high_risk_customers,
            hourly_distribution=hourly_distribution
        )
        
    except Exception as e:
        print(f"‚ùå Erreur dans get_analytics_dashboard: {e}")
        # Retourner des donn√©es par d√©faut en cas d'erreur
        return AnalyticsResponse(
            total_predictions=0,
            churn_rate=0.0,
            avg_confidence=0.85,
            predictions_today=0,
            high_risk_customers=0,
            hourly_distribution={str(i): 0 for i in range(24)}
        )
    
@app.get("/predictions/history", response_model=PredictionHistoryResponse)
async def get_prediction_history(limit: int = 50, offset: int = 0):
    """Endpoint pour r√©cup√©rer l'historique des pr√©dictions depuis MongoDB"""
    try:
        predictions = await mongodb.get_predictions(limit, offset)
        total_count = await mongodb.get_predictions_count()
        
        # Convertir le format MongoDB en format de r√©ponse
        formatted_predictions = []
        for pred in predictions:
            formatted_pred = PredictionResponse(
                prediction_id=pred.get("prediction_id", ""),
                customer_id=pred.get("customer_id"),
                timestamp=pred.get("timestamp", ""),
                churn_probability=pred.get("churn_probability", 0),
                prediction=pred.get("prediction", 0),
                confidence=pred.get("confidence", 0),
                risk_level=pred.get("risk_level", "LOW"),
                message=pred.get("message", ""),
                feature_importance=pred.get("feature_importance")
            )
            formatted_predictions.append(formatted_pred)
        
        return PredictionHistoryResponse(
            predictions=formatted_predictions,
            total_count=total_count,
            has_more=(offset + limit) < total_count
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur r√©cup√©ration historique: {str(e)}")

@app.get("/customers", response_model=List[CustomerResponse])
async def get_customers(limit: int = 50):
    """R√©cup√©rer la liste des clients depuis MongoDB"""
    try:
        customers = await mongodb.get_customers(limit)
        
        formatted_customers = []
        for customer in customers:
            formatted_customer = CustomerResponse(
                id=customer.get("_id", ""),
                name=customer.get("name"),
                email=customer.get("email"),
                phone=customer.get("phone"),
                signup_date=customer.get("signup_date"),
                account_length=customer.get("account_length", 0),
                international_plan=customer.get("international_plan", 0),
                voice_mail_plan=customer.get("voice_mail_plan", 0),
                number_vmail_messages=customer.get("number_vmail_messages", 0),
                total_day_minutes=customer.get("total_day_minutes", 0),
                total_day_calls=customer.get("total_day_calls", 0),
                total_day_charge=customer.get("total_day_charge", 0),
                total_eve_minutes=customer.get("total_eve_minutes", 0),
                total_eve_calls=customer.get("total_eve_calls", 0),
                total_eve_charge=customer.get("total_eve_charge", 0),
                total_night_minutes=customer.get("total_night_minutes", 0),
                total_night_calls=customer.get("total_night_calls", 0),
                total_night_charge=customer.get("total_night_charge", 0),
                total_intl_minutes=customer.get("total_intl_minutes", 0),
                total_intl_calls=customer.get("total_intl_calls", 0),
                total_intl_charge=customer.get("total_intl_charge", 0),
                customer_service_calls=customer.get("customer_service_calls", 0),
                customer_id=customer.get("customer_id"),
                created_at=customer.get("created_at")
            )
            formatted_customers.append(formatted_customer)
        
        return formatted_customers
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur r√©cup√©ration clients: {str(e)}")

@app.post("/model/retrain")
async def retrain_model(background_tasks: BackgroundTasks):
    """Endpoint pour r√©entra√Æner le mod√®le en arri√®re-plan"""
    background_tasks.add_task(train_and_save_model_advanced)
    return {"message": "R√©entra√Ænement du mod√®le d√©marr√© en arri√®re-plan"}

# Fonction d'entra√Ænement avanc√©e (identique √† la version pr√©c√©dente)
def train_and_save_model_advanced():
    """Fonction d'entra√Ænement du mod√®le avec des fonctionnalit√©s avanc√©es"""
    print("üîÆ D√©marrage de l'entra√Ænement du mod√®le avanc√©...")
    
    try:
        # Charger les donn√©es
        data = pd.read_csv('churn-bigml-80.csv')
        
        # Feature engineering avanc√©
        data['Total minutes'] = data['Total day minutes'] + data['Total eve minutes'] + data['Total night minutes']
        data['Total calls'] = data['Total day calls'] + data['Total eve calls'] + data['Total night calls']
        data['Avg call duration'] = data['Total minutes'] / data['Total calls']
        data['Service call ratio'] = data['Customer service calls'] / data['Total calls']
        
        # Encoder les variables cat√©gorielles
        encoder = LabelEncoder()
        categorical_columns = ['International plan', 'Voice mail plan']
        for col in categorical_columns:
            if col in data.columns and data[col].dtype == 'object':
                data[col] = encoder.fit_transform(data[col])
        
        # Pr√©parer les features
        features_to_drop = ['Churn', 'State'] if 'State' in data.columns else ['Churn']
        X = data.drop(columns=features_to_drop, errors='ignore')
        y = data['Churn']
        
        # Split des donn√©es
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        
        # Standardisation
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entra√Ænement de multiple mod√®les
        models = {
            'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42, max_depth=15),
            'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)
        }
        
        best_model = None
        best_score = 0
        model_results = {}
        
        for name, model in models.items():
            print(f"üèãÔ∏è  Entra√Ænement du mod√®le: {name}")
            
            # Validation crois√©e
            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
            
            # Entra√Ænement final
            model.fit(X_train_scaled, y_train)
            
            # Pr√©dictions
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            
            # M√©triques
            accuracy = accuracy_score(y_test, y_pred)
            auc_score = roc_auc_score(y_test, y_pred_proba)
            
            model_results[name] = {
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'accuracy': accuracy,
                'auc_score': auc_score,
                'feature_importance': dict(zip(X.columns, model.feature_importances_)) if hasattr(model, 'feature_importances_') else {}
            }
            
            print(f"üìä {name} - Accuracy: {accuracy:.3f}, AUC: {auc_score:.3f}")
            
            if auc_score > best_score:
                best_score = auc_score
                best_model = model
        
        # Sauvegarde du meilleur mod√®le
        os.makedirs('app/models', exist_ok=True)
        
        joblib.dump(best_model, 'app/models/best_churn_model.pkl')
        joblib.dump(scaler, 'app/models/scaler.pkl')
        joblib.dump(X.columns.tolist(), 'app/models/feature_names.pkl')
        
        # Sauvegarde des m√©triques
        metrics = {
            'training_date': datetime.now().isoformat(),
            'best_model': 'Random Forest' if isinstance(best_model, RandomForestClassifier) else 'Gradient Boosting',
            'best_auc_score': best_score,
            'model_comparison': model_results,
            'feature_names': X.columns.tolist()
        }
        
        with open('app/models/training_metrics.json', 'w') as f:
            json.dump(metrics, f, indent=2)
        
        print("‚úÖ Entra√Ænement avanc√© termin√©!")
        print(f"üéØ Meilleur mod√®le: AUC = {best_score:.3f}")
        
        # Recharger le mod√®le
        load_model()
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'entra√Ænement: {e}")

if __name__ == "__main__":
    import uvicorn
    print("üöÄ Starting Advanced Churn Prediction API with MongoDB on http://localhost:8000")
    print("üìö API Documentation: http://localhost:8000/docs")
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)